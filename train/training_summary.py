#!/usr/bin/env python3
"""
è®­ç»ƒæ€»ç»“è„šæœ¬
ç”Ÿæˆè®­ç»ƒå®Œæˆåçš„æ€»ç»“æŠ¥å‘Š
"""

import sys
from pathlib import Path
import yaml
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def generate_training_summary():
    """ç”Ÿæˆè®­ç»ƒæ€»ç»“"""
    print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ€»ç»“æŠ¥å‘Š")
    print("=" * 50)
    
    # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒå®éªŒ
    runs_dir = Path("runs/train")
    if not runs_dir.exists():
        print("âŒ è®­ç»ƒç»“æœç›®å½•ä¸å­˜åœ¨")
        return
    
    experiments = list(runs_dir.glob("watermark_detector*"))
    if not experiments:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå®éªŒ")
        return
    
    latest_experiment = max(experiments, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ æœ€æ–°å®éªŒ: {latest_experiment}")
    
    # è¯»å–è®­ç»ƒé…ç½®
    config_file = latest_experiment / "args.yaml"
    config = {}
    if config_file.exists():
        with open(config_file, 'r') as f:
            config = yaml.safe_load(f)
    
    # è¯»å–è®­ç»ƒç»“æœ
    results_file = latest_experiment / "results.csv"
    results = []
    if results_file.exists():
        import pandas as pd
        df = pd.read_csv(results_file)
        results = df.to_dict('records')
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    weights_dir = latest_experiment / "weights"
    model_files = {}
    if weights_dir.exists():
        for model_file in ["best.pt", "last.pt"]:
            model_path = weights_dir / model_file
            if model_path.exists():
                size = model_path.stat().st_size / (1024 * 1024)  # MB
                model_files[model_file] = {
                    "path": str(model_path),
                    "size_mb": round(size, 1)
                }
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    summary = {
        "experiment_name": latest_experiment.name,
        "experiment_path": str(latest_experiment),
        "timestamp": datetime.now().isoformat(),
        "config": config,
        "model_files": model_files,
        "training_summary": {}
    }
    
    if results:
        # è·å–æœ€ä½³ç»“æœ
        best_result = max(results, key=lambda x: x.get('metrics/mAP50(B)', 0))
        latest_result = results[-1]
        
        summary["training_summary"] = {
            "total_epochs": len(results),
            "best_epoch": int(best_result.get('epoch', 0)),
            "best_mAP50": round(best_result.get('metrics/mAP50(B)', 0), 4),
            "best_mAP50_95": round(best_result.get('metrics/mAP50-95(B)', 0), 4),
            "final_mAP50": round(latest_result.get('metrics/mAP50(B)', 0), 4),
            "final_mAP50_95": round(latest_result.get('metrics/mAP50-95(B)', 0), 4),
            "final_train_loss": round(latest_result.get('train/box_loss', 0), 4),
            "final_val_loss": round(latest_result.get('val/box_loss', 0), 4)
        }
    
    # ä¿å­˜æ€»ç»“æŠ¥å‘Š
    summary_file = latest_experiment / "training_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ è®­ç»ƒæ€»ç»“å·²ä¿å­˜: {summary_file}")
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ“Š è®­ç»ƒæ€»ç»“:")
    print(f"   å®éªŒåç§°: {summary['experiment_name']}")
    print(f"   è®­ç»ƒè½®æ•°: {summary['training_summary'].get('total_epochs', 'N/A')}")
    print(f"   æœ€ä½³è½®æ•°: {summary['training_summary'].get('best_epoch', 'N/A')}")
    print(f"   æœ€ä½³ mAP50: {summary['training_summary'].get('best_mAP50', 'N/A')}")
    print(f"   æœ€ä½³ mAP50-95: {summary['training_summary'].get('best_mAP50_95', 'N/A')}")
    print(f"   æœ€ç»ˆ mAP50: {summary['training_summary'].get('final_mAP50', 'N/A')}")
    print(f"   æœ€ç»ˆ mAP50-95: {summary['training_summary'].get('final_mAP50_95', 'N/A')}")
    
    print(f"\nğŸ“ æ¨¡å‹æ–‡ä»¶:")
    for model_name, model_info in model_files.items():
        print(f"   {model_name}: {model_info['size_mb']} MB")
    
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"   1. æµ‹è¯•æ¨¡å‹: uv run python train/test_model.py")
    print(f"   2. æŸ¥çœ‹è®­ç»ƒæ›²çº¿: {latest_experiment}/training_curves.png")
    print(f"   3. ä½¿ç”¨æœ€ä½³æ¨¡å‹: {model_files.get('best.pt', {}).get('path', 'N/A')}")
    
    return summary

def create_deployment_guide():
    """åˆ›å»ºéƒ¨ç½²æŒ‡å—"""
    print(f"\nğŸ“‹ åˆ›å»ºéƒ¨ç½²æŒ‡å—...")
    
    guide_content = """# æ°´å°æ£€æµ‹æ¨¡å‹éƒ¨ç½²æŒ‡å—

## æ¨¡å‹æ–‡ä»¶
- **æœ€ä½³æ¨¡å‹**: `runs/train/watermark_detector3/weights/best.pt`
- **æœ€æ–°æ¨¡å‹**: `runs/train/watermark_detector3/weights/last.pt`

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬ä½¿ç”¨
```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO("runs/train/watermark_detector3/weights/best.pt")

# æ£€æµ‹å›¾åƒ
results = model("path/to/image.jpg")

# æ˜¾ç¤ºç»“æœ
results[0].show()
```

### 2. æ‰¹é‡å¤„ç†
```python
# å¤„ç†å¤šä¸ªå›¾åƒ
results = model(["image1.jpg", "image2.jpg", "image3.jpg"])

# å¤„ç†è§†é¢‘
results = model("video.mp4")
```

### 3. é›†æˆåˆ° SoraWatermarkCleaner
```python
# åœ¨ sorawm/watermark_detector.py ä¸­ä½¿ç”¨
from ultralytics import YOLO

class WatermarkDetector:
    def __init__(self, model_path="runs/train/watermark_detector3/weights/best.pt"):
        self.model = YOLO(model_path)
    
    def detect(self, image):
        results = self.model(image)
        return results[0].boxes
```

## æ€§èƒ½æŒ‡æ ‡
- **mAP50**: æ£€æµ‹ç²¾åº¦æŒ‡æ ‡
- **mAP50-95**: ç»¼åˆç²¾åº¦æŒ‡æ ‡
- **æ¨ç†é€Ÿåº¦**: åœ¨ GPU ä¸Šçº¦ 10-20ms/å›¾åƒ

## æ³¨æ„äº‹é¡¹
1. æ¨¡å‹éœ€è¦ PyTorch å’Œ Ultralytics ç¯å¢ƒ
2. å»ºè®®ä½¿ç”¨ GPU è¿›è¡Œæ¨ç†ä»¥è·å¾—æœ€ä½³æ€§èƒ½
3. è¾“å…¥å›¾åƒä¼šè‡ªåŠ¨è°ƒæ•´åˆ° 640x640 å°ºå¯¸
4. æ£€æµ‹ç»“æœåŒ…å«è¾¹ç•Œæ¡†åæ ‡å’Œç½®ä¿¡åº¦

## æ¨¡å‹ä¼˜åŒ–
- å¯ä»¥å¯¼å‡ºä¸º ONNX æ ¼å¼ä»¥æé«˜éƒ¨ç½²æ•ˆç‡
- å¯ä»¥ä½¿ç”¨ TensorRT è¿›è¡Œ GPU åŠ é€Ÿ
- å¯ä»¥é‡åŒ–æ¨¡å‹ä»¥å‡å°‘å†…å­˜å ç”¨
"""
    
    guide_file = Path("TRAINING_DEPLOYMENT_GUIDE.md")
    with open(guide_file, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    
    print(f"ğŸ“„ éƒ¨ç½²æŒ‡å—å·²ä¿å­˜: {guide_file}")

def main():
    """ä¸»å‡½æ•°"""
    # ç”Ÿæˆè®­ç»ƒæ€»ç»“
    summary = generate_training_summary()
    
    # åˆ›å»ºéƒ¨ç½²æŒ‡å—
    create_deployment_guide()
    
    print(f"\nğŸ‰ è®­ç»ƒæ€»ç»“å®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ° runs/train/ ç›®å½•")

if __name__ == "__main__":
    main()

"""
æµ‹è¯•é«˜çº§æ£€æµ‹ç­–ç•¥
éªŒè¯å¤šå°ºåº¦æ£€æµ‹ã€æ™ºèƒ½æ¼æ£€å¤„ç†ã€å¢å¼ºæ©ç ç”Ÿæˆçš„æ•ˆæœ
"""

from pathlib import Path
from sorawm.core import SoraWM
from sorawm.configs import (
    DETECTION_MIN_CONFIDENCE,
    DETECTION_HIGH_CONFIDENCE,
    BBOX_SMOOTHING_WINDOW,
    BBOX_STABILITY_THRESHOLD
)
import sorawm.configs as configs


def test_advanced_detection():
    """æµ‹è¯•é«˜çº§æ£€æµ‹ç­–ç•¥"""
    print("ğŸš€ æµ‹è¯•é«˜çº§æ£€æµ‹ç­–ç•¥")
    print("=" * 60)
    
    # æµ‹è¯•è§†é¢‘è·¯å¾„
    test_video = Path("resources/dog_vs_sam.mp4")
    if not test_video.exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")
        return False
    
    # è¾“å‡ºè·¯å¾„
    output_path = Path("outputs/test_advanced_detection.mp4")
    output_path.parent.mkdir(exist_ok=True, parents=True)
    
    print("ğŸ“Š é«˜çº§æ£€æµ‹ç­–ç•¥é…ç½®:")
    print(f"  æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼: {DETECTION_MIN_CONFIDENCE}")
    print(f"  é«˜ç½®ä¿¡åº¦é˜ˆå€¼: {DETECTION_HIGH_CONFIDENCE}")
    print(f"  å¹³æ»‘çª—å£å¤§å°: {BBOX_SMOOTHING_WINDOW}")
    print(f"  ç¨³å®šæ€§é˜ˆå€¼: {BBOX_STABILITY_THRESHOLD}")
    print()
    
    try:
        print("ğŸ”§ åˆ›å»º SoraWM å®ä¾‹ï¼ˆå¯ç”¨é«˜çº§æ£€æµ‹ï¼‰...")
        sora_wm = SoraWM()
        
        # è¿›åº¦å›è°ƒ
        def progress_callback(percentage: int):
            bar_length = 40
            filled_length = int(bar_length * percentage // 100)
            bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
            print(f'\rå¤„ç†è¿›åº¦: |{bar}| {percentage}%', end='', flush=True)
        
        print("ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘ï¼ˆä½¿ç”¨é«˜çº§æ£€æµ‹ç­–ç•¥ï¼‰...")
        sora_wm.run(test_video, output_path, progress_callback)
        
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        if output_path.exists():
            file_size = output_path.stat().st_size / (1024 * 1024)
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            # è·å–å„ç§ç»Ÿè®¡ä¿¡æ¯
            temporal_stats = sora_wm.detector.temporal_detector.get_detection_statistics()
            advanced_stats = sora_wm.detector.advanced_strategy.get_detection_statistics()
            missed_stats = sora_wm.detector.missed_handler.get_statistics()
            
            print(f"\nğŸ“ˆ æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  æ—¶åºä¸€è‡´æ€§æ£€æµ‹:")
            print(f"    æ£€æµ‹ç‡: {temporal_stats['detection_rate']:.2%}")
            print(f"    å¹³å‡ç½®ä¿¡åº¦: {temporal_stats['avg_confidence']:.3f}")
            print(f"    ç¨³å®šæ£€æµ‹æ¬¡æ•°: {temporal_stats['stable_detection_count']}")
            print(f"    æœ‰ç¨³å®šæ£€æµ‹: {'æ˜¯' if temporal_stats['has_stable_detection'] else 'å¦'}")
            
            print(f"  é«˜çº§æ£€æµ‹ç­–ç•¥:")
            print(f"    æ£€æµ‹ç‡: {advanced_stats['detection_rate']:.2%}")
            print(f"    å¹³å‡ç½®ä¿¡åº¦: {advanced_stats['avg_confidence']:.3f}")
            print(f"    å†å²é•¿åº¦: {advanced_stats['history_length']}")
            
            print(f"  æ¼æ£€å¤„ç†:")
            print(f"    æ£€æµ‹ç‡: {missed_stats['detection_rate']:.2%}")
            print(f"    æ’å€¼æ¬¡æ•°: {missed_stats['interpolation_count']}")
            print(f"    è¿åŠ¨æ¨¡å‹å°±ç»ª: {'æ˜¯' if missed_stats.get('motion_model_ready', False) else 'å¦'}")
            
            return True
        else:
            print("âŒ è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def compare_detection_strategies():
    """å¯¹æ¯”ä¸åŒæ£€æµ‹ç­–ç•¥çš„æ•ˆæœ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æ£€æµ‹ç­–ç•¥å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    test_video = Path("resources/dog_vs_sam.mp4")
    if not test_video.exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")
        return
    
    import time
    
    # æµ‹è¯•åŸºç¡€æ£€æµ‹ç­–ç•¥
    print("ğŸ”„ æµ‹è¯•åŸºç¡€æ£€æµ‹ç­–ç•¥...")
    
    try:
        sora_wm = SoraWM()
        output_basic = Path("outputs/comparison_basic_detection.mp4")
        start_time = time.time()
        sora_wm.run(test_video, output_basic)
        basic_time = time.time() - start_time
        
        basic_temporal_stats = sora_wm.detector.temporal_detector.get_detection_statistics()
        basic_missed_stats = sora_wm.detector.missed_handler.get_statistics()
        
        print(f"âœ… åŸºç¡€ç­–ç•¥å®Œæˆï¼Œè€—æ—¶: {basic_time:.2f} ç§’")
        print(f"   æ£€æµ‹ç‡: {basic_temporal_stats['detection_rate']:.2%}")
        print(f"   æ’å€¼æ¬¡æ•°: {basic_missed_stats['interpolation_count']}")
        
    except Exception as e:
        print(f"âŒ åŸºç¡€ç­–ç•¥å¤±è´¥: {e}")
        basic_time = None
        basic_temporal_stats = None
        basic_missed_stats = None
    
    # æµ‹è¯•é«˜çº§æ£€æµ‹ç­–ç•¥
    print("ğŸš€ æµ‹è¯•é«˜çº§æ£€æµ‹ç­–ç•¥...")
    
    try:
        sora_wm = SoraWM()
        output_advanced = Path("outputs/comparison_advanced_detection.mp4")
        start_time = time.time()
        sora_wm.run(test_video, output_advanced)
        advanced_time = time.time() - start_time
        
        advanced_temporal_stats = sora_wm.detector.temporal_detector.get_detection_statistics()
        advanced_advanced_stats = sora_wm.detector.advanced_strategy.get_detection_statistics()
        advanced_missed_stats = sora_wm.detector.missed_handler.get_statistics()
        
        print(f"âœ… é«˜çº§ç­–ç•¥å®Œæˆï¼Œè€—æ—¶: {advanced_time:.2f} ç§’")
        print(f"   æ£€æµ‹ç‡: {advanced_temporal_stats['detection_rate']:.2%}")
        print(f"   æ’å€¼æ¬¡æ•°: {advanced_missed_stats['interpolation_count']}")
        print(f"   è¿åŠ¨æ¨¡å‹å°±ç»ª: {'æ˜¯' if advanced_missed_stats['motion_model_ready'] else 'å¦'}")
        
    except Exception as e:
        print(f"âŒ é«˜çº§ç­–ç•¥å¤±è´¥: {e}")
        advanced_time = None
        advanced_temporal_stats = None
        advanced_advanced_stats = None
        advanced_missed_stats = None
    
    # å¯¹æ¯”ç»“æœ
    if (basic_time and advanced_time and 
        basic_temporal_stats and advanced_temporal_stats and
        basic_missed_stats and advanced_missed_stats):
        
        print(f"\nğŸ“ˆ æ£€æµ‹ç­–ç•¥å¯¹æ¯”:")
        print(f"  åŸºç¡€ç­–ç•¥:")
        print(f"    å¤„ç†æ—¶é—´: {basic_time:.2f} ç§’")
        print(f"    æ£€æµ‹ç‡: {basic_temporal_stats['detection_rate']:.2%}")
        print(f"    æ’å€¼æ¬¡æ•°: {basic_missed_stats['interpolation_count']}")
        
        print(f"  é«˜çº§ç­–ç•¥:")
        print(f"    å¤„ç†æ—¶é—´: {advanced_time:.2f} ç§’")
        print(f"    æ£€æµ‹ç‡: {advanced_temporal_stats['detection_rate']:.2%}")
        print(f"    æ’å€¼æ¬¡æ•°: {advanced_missed_stats['interpolation_count']}")
        print(f"    è¿åŠ¨æ¨¡å‹å°±ç»ª: {'æ˜¯' if advanced_missed_stats.get('motion_model_ready', False) else 'å¦'}")
        
        # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
        detection_improvement = (advanced_temporal_stats['detection_rate'] - 
                               basic_temporal_stats['detection_rate'])
        interpolation_improvement = (advanced_missed_stats['interpolation_count'] - 
                                   basic_missed_stats['interpolation_count'])
        
        print(f"\nğŸ¯ æ”¹è¿›æ•ˆæœ:")
        print(f"  æ£€æµ‹ç‡æå‡: {detection_improvement:+.2%}")
        print(f"  æ’å€¼æ¬¡æ•°å˜åŒ–: {interpolation_improvement:+d}")
        print(f"  è¿åŠ¨æ¨¡å‹: {'å¯ç”¨' if advanced_missed_stats.get('motion_model_ready', False) else 'æœªå¯ç”¨'}")
        
        if detection_improvement > 0:
            print("ğŸ‰ é«˜çº§æ£€æµ‹ç­–ç•¥æå‡äº†æ£€æµ‹ç²¾åº¦!")
        else:
            print("âš ï¸  æ£€æµ‹ç²¾åº¦éœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")


def test_multi_scale_detection():
    """æµ‹è¯•å¤šå°ºåº¦æ£€æµ‹"""
    print("\n" + "=" * 60)
    print("ğŸ” å¤šå°ºåº¦æ£€æµ‹æµ‹è¯•")
    print("=" * 60)
    
    from sorawm.utils.advanced_detector import AdvancedDetectionStrategy
    from sorawm.watermark_detector import SoraWaterMarkDetector
    import cv2
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    detector = SoraWaterMarkDetector()
    strategy = AdvancedDetectionStrategy()
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    test_video = Path("resources/dog_vs_sam.mp4")
    if not test_video.exists():
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")
        return
    
    # è¯»å–ç¬¬ä¸€å¸§ä½œä¸ºæµ‹è¯•
    cap = cv2.VideoCapture(str(test_video))
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("âŒ æ— æ³•è¯»å–æµ‹è¯•å¸§")
        return
    
    print("ğŸ§ª æµ‹è¯•å¤šå°ºåº¦æ£€æµ‹...")
    
    # æµ‹è¯•ä¸åŒå°ºåº¦
    scales = [0.8, 0.9, 1.0, 1.1, 1.2]
    results = []
    
    for scale in scales:
        result = strategy.multi_scale_detection(detector, frame, [scale])
        results.append((scale, result))
        
        print(f"å°ºåº¦ {scale}: æ£€æµ‹={result['detected']}, "
              f"ç½®ä¿¡åº¦={result['confidence']:.3f}, "
              f"å¤šå°ºåº¦={result.get('multi_scale', False)}")
    
    # æµ‹è¯•èåˆæ£€æµ‹
    print("\nğŸ”— æµ‹è¯•å¤šå°ºåº¦èåˆæ£€æµ‹...")
    fusion_result = strategy.multi_scale_detection(detector, frame, scales)
    
    print(f"èåˆç»“æœ: æ£€æµ‹={fusion_result['detected']}, "
          f"ç½®ä¿¡åº¦={fusion_result['confidence']:.3f}, "
          f"å¤šå°ºåº¦={fusion_result.get('multi_scale', False)}")
    
    # ç»Ÿè®¡ç»“æœ
    individual_detections = sum(1 for _, result in results if result['detected'])
    fusion_detection = 1 if fusion_result['detected'] else 0
    
    print(f"\nğŸ“Š å¤šå°ºåº¦æ£€æµ‹ç»Ÿè®¡:")
    print(f"  å•å°ºåº¦æ£€æµ‹æˆåŠŸ: {individual_detections}/{len(scales)}")
    print(f"  èåˆæ£€æµ‹æˆåŠŸ: {'æ˜¯' if fusion_detection else 'å¦'}")
    print(f"  èåˆç½®ä¿¡åº¦: {fusion_result['confidence']:.3f}")


if __name__ == "__main__":
    import sys
    
    # åŸºæœ¬é«˜çº§æ£€æµ‹æµ‹è¯•
    success = test_advanced_detection()
    
    # å¦‚æœåŸºæœ¬æµ‹è¯•æˆåŠŸï¼Œè¿›è¡Œå¯¹æ¯”æµ‹è¯•
    if success and len(sys.argv) > 1:
        if sys.argv[1] == "--compare":
            compare_detection_strategies()
        elif sys.argv[1] == "--multiscale":
            test_multi_scale_detection()
        elif sys.argv[1] == "--all":
            compare_detection_strategies()
            test_multi_scale_detection()
    
    if success:
        print("\nğŸ‰ é«˜çº§æ£€æµ‹ç­–ç•¥æµ‹è¯•å®Œæˆ!")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ --compare è¿›è¡Œç­–ç•¥å¯¹æ¯”ï¼Œ--multiscale æµ‹è¯•å¤šå°ºåº¦æ£€æµ‹ï¼Œ--all è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    else:
        print("\nâŒ é«˜çº§æ£€æµ‹ç­–ç•¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

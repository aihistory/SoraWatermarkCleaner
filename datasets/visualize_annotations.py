#!/usr/bin/env python3
"""
æ ‡æ³¨å¯è§†åŒ–è„šæœ¬
åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ŒéªŒè¯æ ‡æ³¨è´¨é‡
"""

import cv2
import numpy as np
import sys
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sorawm.configs import ROOT

def draw_yolo_bbox(image: np.ndarray, center_x: float, center_y: float, 
                   width: float, height: float, class_id: int = 0, 
                   color: Tuple[int, int, int] = (0, 255, 0)) -> np.ndarray:
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶ YOLO æ ¼å¼çš„è¾¹ç•Œæ¡†
    
    Args:
        image: è¾“å…¥å›¾åƒ
        center_x: ä¸­å¿ƒç‚¹Xåæ ‡ (ç›¸å¯¹åæ ‡ 0-1)
        center_y: ä¸­å¿ƒç‚¹Yåæ ‡ (ç›¸å¯¹åæ ‡ 0-1)
        width: å®½åº¦ (ç›¸å¯¹åæ ‡ 0-1)
        height: é«˜åº¦ (ç›¸å¯¹åæ ‡ 0-1)
        class_id: ç±»åˆ«ID
        color: è¾¹ç•Œæ¡†é¢œè‰² (BGRæ ¼å¼)
        
    Returns:
        ç»˜åˆ¶äº†è¾¹ç•Œæ¡†çš„å›¾åƒ
    """
    img_height, img_width = image.shape[:2]
    
    # è½¬æ¢ä¸ºç»å¯¹åæ ‡
    center_x_abs = int(center_x * img_width)
    center_y_abs = int(center_y * img_height)
    width_abs = int(width * img_width)
    height_abs = int(height * img_height)
    
    # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
    x1 = center_x_abs - width_abs // 2
    y1 = center_y_abs - height_abs // 2
    x2 = center_x_abs + width_abs // 2
    y2 = center_y_abs + height_abs // 2
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†
    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
    
    # ç»˜åˆ¶ç±»åˆ«æ ‡ç­¾
    label = f"watermark (ID: {class_id})"
    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
    
    # æ ‡ç­¾èƒŒæ™¯
    cv2.rectangle(image, (x1, y1 - label_size[1] - 10), 
                  (x1 + label_size[0], y1), color, -1)
    
    # æ ‡ç­¾æ–‡å­—
    cv2.putText(image, label, (x1, y1 - 5), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return image

def visualize_annotations(image_path: Path, label_path: Path, 
                         output_path: Path = None) -> np.ndarray:
    """
    å¯è§†åŒ–å•ä¸ªå›¾åƒçš„æ ‡æ³¨
    
    Args:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        å¯è§†åŒ–åçš„å›¾åƒ
    """
    # è¯»å–å›¾åƒ
    image = cv2.imread(str(image_path))
    if image is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
    
    # è¯»å–æ ‡ç­¾æ–‡ä»¶
    if not label_path.exists():
        print(f"âš ï¸  æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_path}")
        return image
    
    with open(label_path, 'r') as f:
        lines = f.readlines()
    
    # ç»˜åˆ¶æ¯ä¸ªæ ‡æ³¨
    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
            
        parts = line.split()
        if len(parts) != 5:
            continue
            
        try:
            class_id = int(parts[0])
            center_x = float(parts[1])
            center_y = float(parts[2])
            width = float(parts[3])
            height = float(parts[4])
            
            # é€‰æ‹©é¢œè‰²
            color = colors[i % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            image = draw_yolo_bbox(image, center_x, center_y, width, height, 
                                 class_id, color)
        except ValueError:
            continue
    
    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    if output_path:
        cv2.imwrite(str(output_path), image)
        print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
    
    return image

def visualize_dataset_sample(dataset_dir: Path, split: str = "train", 
                           num_samples: int = 5, output_dir: Path = None):
    """
    å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬
    
    Args:
        dataset_dir: æ•°æ®é›†ç›®å½•
        split: æ•°æ®é›†åˆ†å‰² (train/val/test)
        num_samples: å¯è§†åŒ–æ ·æœ¬æ•°é‡
        output_dir: è¾“å‡ºç›®å½•
    """
    images_dir = dataset_dir / "images" / split
    labels_dir = dataset_dir / "labels" / split
    
    if not images_dir.exists():
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        return
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png"))
    
    if not image_files:
        print(f"âŒ åœ¨ {images_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    import random
    random.seed(42)
    sample_files = random.sample(image_files, min(num_samples, len(image_files)))
    
    print(f"ğŸ¨ å¯è§†åŒ– {len(sample_files)} ä¸ª {split} é›†æ ·æœ¬...")
    
    for i, image_file in enumerate(sample_files):
        label_file = labels_dir / f"{image_file.stem}.txt"
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_dir:
            output_path = output_dir / f"visualization_{i+1}_{image_file.name}"
            output_dir.mkdir(exist_ok=True, parents=True)
        else:
            output_path = None
        
        try:
            # å¯è§†åŒ–æ ‡æ³¨
            vis_image = visualize_annotations(image_file, label_file, output_path)
            
            # æ˜¾ç¤ºå›¾åƒï¼ˆå¦‚æœå¯èƒ½ï¼‰
            try:
                cv2.imshow(f"Annotation Visualization - {image_file.name}", vis_image)
                print(f"ğŸ“· æ˜¾ç¤ºå›¾åƒ: {image_file.name} (æŒ‰ä»»æ„é”®ç»§ç»­)")
                cv2.waitKey(0)
                cv2.destroyAllWindows()
            except:
                print(f"ğŸ“· æ— æ³•æ˜¾ç¤ºå›¾åƒ: {image_file.name}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_file.name}: {e}")

def main():
    """ä¸»å‡½æ•°"""
    dataset_dir = ROOT / "datasets" / "coco8"
    
    if not dataset_dir.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        print("è¯·å…ˆè¿è¡Œ setup_yolo_dataset.py å’Œ split_dataset.py")
        return
    
    # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
    output_dir = ROOT / "datasets" / "visualizations"
    output_dir.mkdir(exist_ok=True, parents=True)
    
    print("ğŸ¨ å¼€å§‹å¯è§†åŒ–æ ‡æ³¨...")
    
    # å¯è§†åŒ–å„ä¸ªåˆ†å‰²é›†çš„æ ·æœ¬
    for split in ['train', 'val', 'test']:
        print(f"\nğŸ“Š å¯è§†åŒ– {split} é›†æ ·æœ¬:")
        visualize_dataset_sample(dataset_dir, split, num_samples=3, 
                               output_dir=output_dir / split)
    
    print(f"\nâœ… å¯è§†åŒ–å®Œæˆ! ç»“æœä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()
